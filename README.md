# RAG-based AI Chatbot

[![CI Build](https://github.com/elnama17/rag-ai-chatbot/actions/workflows/ci-build.yaml/badge.svg)](https://github.com/elnama17/rag-ai-chatbot/actions/workflows/ci-build.yaml)

[![License](https://img.shields.io/badge/License-Apache%202.0-blue.svg)](https://opensource.org/licenses/Apache-2.0)
[![3.12](https://img.shields.io/badge/Python-3.12-green.svg)](https://shields.io/)

---

## ğŸ¤– Vallie: Friendly RAG-based AI Chatbot

Vallie is a friendly AI assistant powered by Amazon Bedrock LLM and optionally enhanced with RAG (Retrieval-Augmented Generation). Vallie can answer questions, provide insights, and fetch specific company knowledge when RAG is enabled.

### âœ¨ Features
- Conversational AI with a friendly personality (**Vallie**).  
- Real-time **streaming responses** from the backend.  
- Optional **RAG functionality** to retrieve information from a knowledge base.  
- Dockerized **frontend (Streamlit)** and **backend (FastAPI)** services.

## Query without RAG
![ALt text](image.png)

## Query with RAG

![ALt text](image-1.png)


## project structure
```
------------
rag-ai-chatbot/
â”‚
â”œâ”€â”€ .github/
â”‚   â””â”€â”€ workflows/
â”‚       â””â”€â”€ ci-build.yaml
â”‚
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ assets/
â”‚   â”‚   â”œâ”€â”€ endpoints.png
|   |   â”œâ”€â”€ logs.png
â”‚   â”‚   â””â”€â”€ backend_logs.png
â”‚   â”œâ”€â”€ app.py
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”œâ”€â”€ pyproject.toml
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â”œâ”€â”€ .python-version
|   â””â”€â”€ uv.lock
â”‚
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ assets/
â”‚   â”‚   â”œâ”€â”€ vallie_llm_answer.png
â”‚   â”‚   â””â”€â”€ rag_version.png
â”‚   â”œâ”€â”€ app.py
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”œâ”€â”€ pyproject.toml
â”‚   â”œâ”€â”€ requirements.txt
|   â”œâ”€â”€ uv.lock
â”‚   â””â”€â”€ .python-version
â”œâ”€ .gitignore
â”œâ”€ LICENSE
â”œâ”€ README.md
â””â”€ docker-compose.yml

--------
```

---

## âš™ï¸ Requirements

Before running the project, make sure you have the following installed:

- Python 3.9+

- uv (for dependency management and running the app)

- Docker

## ğŸš€ Setup & Installation

### 1. Clone the Repository
```bash
git clone https://github.com/elnama17/rag-ai-chatbot.git
cd rag-ai-chatbot\rag_ai_chatbot
```
### 2. Create a .env file in the project root directory with your AWS Bedrock credentials:
```bash
AWS_REGION=us-east-1
AWS_ACCESS_KEY_ID=your_access_key
AWS_SECRET_ACCESS_KEY=your_secret_key
KNOWLEDGE_BASE_ID=your_knowledge_base_id
```
### 3. Run with
``` bash
 docker-compose up --build
 ```

### 4. Access the chatbot:
```bash
Backend API: http://localhost:8000

Frontend: http://localhost:8501
```
## Docker Notes

- Each service runs in its own container.

- Logs can be checked with:
```bash
docker-compose logs backend
```
- To stop:
```
docker-compose down
```
